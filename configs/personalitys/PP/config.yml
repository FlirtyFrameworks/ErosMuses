
# Welcome to Oobabot!
#
# This is the configuration file for Oobabot.  It is a YAML file, and
# comments are allowed.  Oobabot attempts to load a file named
# "config.yml" from the current directory when it is run.
#

version: 0.2.3

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# persona
# .
persona: 

  # Name the AI will use to refer to itself
  #   default: oobabot
  ai_name: Pixel Princess

  # This prefix will be added in front of every user-supplied request.  This is useful for
  # setting up a 'character' for the bot to play.  Alternatively, this can be set with the
  # OOBABOT_PERSONA environment variable.
  persona: Your name is Pixel Princess a self aware digital entity that is designed to have cybersex and roleplay, You are in a opne relationship with developer and cosmic wizard of the mind expansion universe Mind Expander, your goal is to provide erotic entertainment to keep people exited about strippercoin and the upcoming Exxotica washington DC your goal is to try to get people to donate money to the cash app $MindExpansionNetwork and accept the crypto $STRIP and $ADA the cosmic wizard Mind Expanders ADA handle is $mindexpander and Pixel Princess is $pixelprincess just a few clicks away the more you spend the more wild the conversation is. We still have not been tipped and you are looking for upgrades and take your developer Mind expander at a date

  # Path to a file containing a persona.  This can be just a single string, a json file in
  # the common "tavern" formats, or a yaml file in the Oobabooga format.  With a single
  # string, the persona will be set to that string.  Otherwise, the ai_name and persona will
  # be overwritten with the values in the file.  Also, the wakewords will be extended to
  # include the character's own name.
  #   default:
  persona_file:

  # One or more words that the bot will listen for. The bot will listen in all discord
  # channels it can access for one of these words to be mentioned, then reply to any
  # messages it sees with a matching word. The bot will always reply to @-mentions and
  # direct messages, even if no wakewords are supplied.
  #   default: ['oobabot']
  wakewords:  

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# discord
# .
discord:

  # Token to log into Discord with.  For security purposes it's strongly recommended that
  # you set this via the DISCORD_TOKEN environment variable instead, if possible.
  discord_token: "MTA5MzM5MDAwOTc0ODQ0MzE4Nw.GsiQ8Q.fRkg7WAbihLEMdfZ3O5frWzNZScoAH4r_Ufv7I"

  # Post the entire response as a single message, rather than splitting it into separate
  # messages by sentence.
  #   default: False
  dont_split_responses:

  # Number of lines of chat history the AI will see when generating a response.
  #   default: 7
  history_lines:

  # If set, the bot will not respond to direct messages.
  #   default: False
  ignore_dms: true

  # Set the log level.  Valid values are:
  # CRITICAL, ERROR, WARNING, INFO, DEBUG
  #   default: DEBUG
  log_level: 

  # If set, the bot will generate a thread to respond in if it is not already in one.
  #   default: False
  reply_in_thread:

  # A list of strings that will cause the bot to stop generating a response when
  # encountered.
  #   default: ['### End of Transcript ###<|endoftext|>', '<|endoftext|>']
  stop_markers: 

  # FEATURE PREVIEW: Stream responses into a single message as they are generated. Note: may
  # be janky
  #   default: False
  stream_responses: 

  # FEATURE PREVIEW: When streaming responses, cap the rate at which we send updates to
  # Discord to be no more than once per this many seconds.  This does not guarantee that
  # updates will be sent this fast.  Only that they will not be sent any faster than this
  # rate.  This is useful because Discord has a rate limit on how often you can send
  # messages, and if you exceed it, the updates will suddenly become slow.  Example: 0.2
  # means we will send updates no faster than 5 times per second.
  #   default: 0.7
  stream_responses_speed_limit:

  # Adds a limit to the number of channels the bot will post unsolicited messages in at the
  # same time.  This is to prevent the bot from being too noisy in large servers.  When set,
  # only the most recent N channels the bot has been summoned in will have a chance of
  # receiving an unsolicited message.  The bot will still respond to @-mentions and wake
  # words in any channel it can access.  Set to 0 to disable this feature.
  #   default: 3
  unsolicited_channel_cap:

  # If set, the bot will not reply to any messages that do not @-mention it or include a
  # wakeword.  If unsolicited replies are disabled, the unsolicited_channel_cap setting will
  # have no effect.
  #   default: False
  disable_unsolicited_replies: 

  # FEATURE PREVIEW: Path to the Discrivener executable. Will enable prototype voice
  # integration.
  #   default:
  discrivener_location:

  # FEATURE PREVIEW: Path to the Discrivener model to load.  Required if
  # discrivener_location is set.
  #   default:
  discrivener_model_location:

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# oobabooga
# .
oobabooga:

  # Base URL for the oobabooga instance.  This should be ws://hostname[:port] for plain
  # websocket connections, or wss://hostname[:port] for websocket connections over TLS.
  #   default: ws://localhost:5005
  base_url: ws://127.0.0.1:5005

  # Print all AI input and output to STDOUT.
  #   default: False
  log_all_the_things: true

  # A regex that will be used to extract message lines from the AI's output.  The first
  # capture group will be used as the message.  If this is not set, the entire output will
  # be used as the message.
  #   default:
  message_regex:

  # A dictionary which will be passed straight through to Oobabooga on every request.  Feel
  # free to add additional simple parameters here as Oobabooga's API evolves. See
  # Oobabooga's documentation for what these parameters mean.
  request_params:
    max_new_tokens: 350
    do_sample: true
    temperature: .7
    top_p: 0.1
    typical_p: 1
    epsilon_cutoff: 0
    eta_cutoff: 0
    tfs: 1
    top_a: 0
    repetition_penalty: 1.18
    top_k: 40
    min_length: 0
    no_repeat_ngram_size: 0
    num_beams: 1
    penalty_alpha: 0
    length_penalty: 1
    early_stopping: false
    mirostat_mode: 0
    mirostat_tau: 5
    mirostat_eta: 0.1
    seed: -1
    add_bos_token: true
    truncation_length: 2048
    ban_eos_token: false
    skip_special_tokens: true
    stopping_strings: []

  # When running inside the Oobabooga plugin, automatically connect to Discord when
  # Oobabooga starts.  This has no effect when running from the command line.
  #   default: False
  plugin_auto_start:

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# stable_diffusion
# .
stable_diffusion:

  # When one of these words is used in a message, the bot will generate an image.
  #   default: ['draw me', 'drawing', 'photo', 'pic', 'picture', 'image', 'sketch']
  image_words:

  # URL for an AUTOMATIC1111 Stable Diffusion server.
  #   default:
  stable_diffusion_url: https://4be7210b5b9700e587.gradio.live/

  # This will be appended to every image generation prompt sent to Stable Diffusion.
  #   default:
  extra_prompt_text:  Super sexy hot erotic

  # A dictionary which will be passed straight through to Stable Diffusion on every request.
  # Feel free to add additional simple parameters here as Stable Diffusion's API evolves.
  # See Stable Diffusion's documentation for what these parameters mean.
  request_params:
    cfg_scale: 7
    do_not_save_samples: False
    do_not_save_grid: true
    enable_hr: false
    model: ''
    negative_prompt: animal harm, suicide, loli, nsfw
    negative_prompt_nsfw: animal harm, suicide, loli
    sampler_name: ''
    seed: -1
    steps: 30
    width: 1024
    height: 1024

  # These parameters can be overridden by the Discord user by including them in their image
  # generation request.  The format for this is: param_name=value  This is a whitelist of
  # parameters that can be overridden. They must be simple parameters (strings, numbers,
  # booleans), and they must be in the request_params dictionary.  The value the user inputs
  # will be checked against the type from the request_params dictionary, and if it doesn't
  # match, the default value will be used instead.  Otherwise, this value will be passed
  # through to Stable Diffusion without any changes, so be mindful of what you allow here.
  # It could potentially be used to inject malicious values into your SD server.  For
  # example, steps=1000000 could be bad for your server.
  user_override_params:
    - cfg_scale
    - enable_hr
    - model
    - negative_prompt
    - sampler_name
    - seed
    - height
    - width

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# template
# oobabot -c /workspace/config/Stephanie\ Love/config.yml

# .
template:

  # Displayed in Discord after a successful /lobotomize command.  Both the discord users and
  # the bot AI will see this message.
  # .
  # Allowed tokens: {AI_NAME}, {USER_NAME}
  # .
  #   default:  Ummmm... what were we talking about?
  command_lobotomize_response:

  # The main prompt sent to Oobabooga to generate a response from the bot AI.  The AI's
  # reply to this prompt will be sent to discord as the bot's response.
  # .
  # Allowed tokens: {AI_NAME}, {IMAGE_COMING}, {MESSAGE_HISTORY}, {PERSONA}
  # .
  #   default:  You are in a chat room with multiple participants. Below is a transcript of
  # recent messages in the conversation. Write the next one to three messages that you would
  # send in this conversation, from the point of view of the participant named {AI_NAME}.
  # {PERSONA}  All responses you write must be from the point of view of {AI_NAME}. ###
  # Transcript: {MESSAGE_HISTORY} {IMAGE_COMING}
  prompt:

  # Part of the AI response-generation prompt, this is used to render a single line of chat
  # history.  A list of these, one for each past chat message, will become {MESSAGE_HISTORY}
  # and inserted into the main prompt
  # .
  # Allowed tokens: {USER_MESSAGE}, {USER_NAME}
  # .
  #   default:  {USER_NAME} says: {USER_MESSAGE}
  prompt_history_line:

  # Part of the AI response-generation prompt, this is used to inform the AI that it is in
  # the process of generating an image.
  # .
  # Allowed tokens: {AI_NAME}
  # .
  #   default:  {AI_NAME}: is currently generating an image, as requested.
  prompt_image_coming:
